Intelligence has been defined as ``an agent’s ability to achieve goals in a wide range of environments.'' (Legg and Hutter, 2007 CITE) and ``skill-acquisition efficiency'' with respect to available information (Chollet 2019 CITE). While its mode of expression varies between and even within natural and artificial settings, \we extract overarching principles and comparisons in this section. \Our aim is not to exhaust every thought and theory but only to provide a background for introducing \PGI. See CITE for a more extensive discussion.

\subsection{Energetic grounding}

\begin{WrapText}

\textbf{How can energy be ``free''?}

Energy is never actually free, but from the context of any thermodynamic system only some internal energy is free to cross the system barrier after entropy imposes its tax. Consider the relationships between Gibbs free energy $G$, Helmholtz free energy $F$, Grand potential $\mathrm{\phi_{G}}$, and Kullback Leibler divergence $\kld{p}{q}$\citep[2]{Hafner2020}:

\begin{alignat*}{4}
&& G    &{} = {}&& H + PV && - TS \\
&& F    &{} = {}&& U      && - TS \\
&& \mathrm{\phi_{G}} &{} = {}&& E      && - TS - \mu N \\
&& \underbrace{ \kld{p}{q} }_{\text{free energy}} &{} = {}&& \stackengine{0pt}{\phantom{H + PV}}{\underbrace{ H(p,q) }_{\mathclap{\text{bound energy}}} }{U}{l}{F}{T}{L} && - \underbrace{ H(p) }_{\text{entropy}}
\end{alignat*}

% \[{{} \underbrace{\phantom{\kld{p}{q}}}_{\mathclap{\text{free energy}}}}  \underbrace{\phantom{H + PV}}_{ \mathclap {\text{bound energy} }} \phantom{- {}}\underbrace{ \phantom{ TS - \mu N } }_{\mathclap{\text{entropy}}} \phantom{\underbrace{}_{}}\]

%& \kld{p}{q} &&{} = {}&& H(p,q) && - H(p) \\[-2.7ex]
%& {\underbrace{\phantom{\kld{p}{q}}}_{\text{free energy}}} && && \underbrace{\phantom{H + PV}}_{\text{bound energy}} && \phantom{- {}}\underbrace{ \phantom{ TS - \mu N } }_{\text{entropy}} 

%& \underbrace{ \kld{p}{q} }_{\text{free energy}} &&{} = {}&& \stackengine{0pt}{\phantom{H + PV}}{\underbrace{ H(p,q) }_{\text{bound energy}}}{U}{c}{F}{T}{L}  && - \underbrace{ H(p) }_{\text{entropy}}

Also note interdisciplinary similarities in measures of difference:
\begin{itemize}
 \item energetic inequalities
 \item neuron firing and predictive coding
 \item (allostatic) stress
 \item economic disequilibrium
 \item the definition of a problem
\end{itemize}

\end{WrapText}

Intelligence begins with information (CITE) which, in turn, depends on energy. Under any probability distribution $p$, information theory even equates information with energy by $E(x) = - \log{p(x)} $ (CITE). With this negative log-likelihood relationship, it is easy to see that unexpected events are therefore energetic ones. For instance, signaling with prior-optimized codebook, the cross entropy of a signal directly relates both electrical energy consumed and information transmitted. (CITE) Likewise EEG's are used to approximate the information processing involvement of a brain region by measuring its glucose energy metabolism. (CITE)

In all natural settings, free energy minimization is the norm, and its increase is an exception: objects descend potential wells; virtual particles dissapate; the princple of least action obtains a minimal route for system evolution. In turn, decrease of free energy accompanies increase in entropy: structured arangements evaporate; gas pressures equalize; wavefunctions spread out. Notably, the Casmir force directly attracts of repels matter apart from any of the four fundamental forces such that expected energy homogenizes. 

Neural networks represent a thermodynamic system of weights and activations, so it is only propper to extend the free energy minimizing motif in deep learning. Minimizing Kullback Leibler divergence between a model $p_\theta(y|x)$ on a data-generating distribution $\tau(x,y)$ has the convenient property of decreasing expected loss while also encouraging maximum entropy: $\min_\theta \kld{ p_\theta(y|x)\tau(x) }{ \tau(x,y) } = H(p_\theta(y|x)\tau(x), \tau(x,y)) - H(p_\theta(y|x)\tau(x))$ (See Box ``How can energy be ``free''?''). Additionally, the thermodynamic perspective identifies phase transitions in training which if properly understood can accelerate convergence.

Free energy minimization does not stop with training loss however. The actual algorithmic implementations of intelligence should also be made as resource efficent as possible. While state of the art machine learning systems show remarkable performance in a variety of problem domains, this is generally achieved with massive amounts of physical energy, huge datasets, and expensive training budgets. Using ``skill acquisition efficency [\dots] with respect to information [and] task [\dots]'' (MAKE SURE THIS QUOTE IS CORRECT) as a working definition for intelligence, the GPT-3 is no more intelligent than its predecessor transformers. Contrarily, the parameter-performance log relationship \citep[11]{Brown2020} indicates that while its skill may be greator, this model is \textit{less} intelligent than its smaller relatives in tasks not demanding GPT-3 performance. Real progress in intelligence will likely require a departure from the biologically imposible backpropagation through time to efficently tune trillions of parameters.

Life stands in defiance to the entropic trend, yet even in the struggle for survival, living systems continually optimize energy expendature. By the energy-information relationship, this means minimal information transfer and greatest potential for intelligence. For example, homeostatic mechanisms work to equalize energy production and consumption. This results in minimal free energy, optimal energy expendature, and ``survival intelligence'' (CITE). Genetic code likewise gives the muscular-skeletal system innate ``mechanical intelligence'' which `ofloads' some of the locomotive learning that a vertabrae's brain must perform. (Davide Zappetti CITE but that article is about robots not natural systems). From allostatic perspective, living systems represent a prior expectation of their environmental state and adapt their input and output modalities to the expected range of energy transfer. It follows that as actual and expected environments diverge, stress increases and survival imposes a greator information and energetic tax to maintain order. Again, probability expectation maximization accompanies energy minimization, hence control over the environment and intelligence.

Following the Paradigm of Allostatic Orchestration, machine learning likewise adjusts a neural network's parameters to the expected range of input and output signals. Even within a neural network, each layer may be understood as `absorbing' some of the data's energy as it travels to the output layer. With tools from linear algebra, it is easy to observe that each layer when interpretted as a random variable bijector can only output as much free energy as it recieves. Like a resistor chain, as activations ascend a classic DNN heirarchy, they may experience various coordinate transforms, but the information-energy they represent only grows in entropy, hence minimizing free energy.

It should be noted that intelligently meeting the energy challange in nature is not simply about on storing away as much energy as possible, but equalizing energy intake and expenderture. Sustained positive free energy is just debilitating as negative extremes.\footnote{In mobile life forms, selection pressures favor this extreme over the other. As this is not a common natural stressor, most animals simply do not need to carry the mechanisms to intelligently handle high amounts of free energy and suffer from resulting stress. } For instance, chronic elevated levels of mobilized energy and its indicators such as blood sugar, free fatty acids, cortisol, and blood pressure are associated with inflammation, diabetes, immunosuppression, ulceration, corinary heart disease, and hypertension. Likewise, extreme stressor exposure often maladaptively leads to PTSD. (GIVE SOME MORE MENTAL DISORDERS)

\begin{wrapfigure}{r}{0.5\textwidth}
 \centering
 \includegraphics{energy_minimization_local_and_global.jpg}
 \label{fig:1}
 \caption{Local energy minimization results in global intelligence. Explain in detail what's happening in this figure. \dots Intelligent behavior minimizes the energy stress imposed by the organism's sensors and actuators. Reprinted with permission from \cite{Vergara2019}.}
\end{wrapfigure}

The brain exemplifies the principle of free energy minimization. Consuming 20\% of the average human's (CHECK) basal metabolic energy in an organ only 1.5 kg. (3 lbs.) (CHECK), it quickly dies in the abscense of a steady flow of energy. The brain cannot simply maintain large internal energy reserves because the limited signal routing speed of neurons favors maximum packing density. The challange is therefore on individual eurons to remain extremely sensitive to extracellular energy and balance a tight budget. Energetically expensive processes like generating spike trains -- especially over long axons -- must kept to a bare minimum. However energy excess is equally dangerous; unchecked, hyperglyemia leads to neuroinflammation and ultimately, cell death. To cope with energy stress in either direction, neurons regulate nonessential energy consuming or producing processes according to free energy availability. If energy is short, cell synaptic junctions become more resistive and the spiking threshold increases. This decreases the frequency of energetic signaling. Over longer time scales, outgoing dentritic count may even decrease. On the other hand, if there is leftover energy after regular cell processes occur, signal cascades tune the neuron to increase sensitive to its present and potential neuron neighbors: synaptic junctions become less resistive, the spiking thresholds decreases, and cell growth increases -- even branching out to form new dendrites. In either case, the neuron adapts to maintain dynamic equalibrium between energy supply and demand. Of course, essential cell maintenance processes regularize this adaptation to prevent it from collapsing to zero. The network scale effect is: steady free energy minimization contributes positively to information processing. In turn, this local principle promotes global intelligence. (See Figure ref{fig:1}) Experiments have shown that even in the abscence of a reward system or natural body, this local energy stress is a sufficent reward signal for isotropic sections of cortical tissue to learn robotic vehicle control. \cite{Vergara2019}

It comes as no surprise therefore that estimated cost minimization is the norm in behavioral psychology and emergant sciences: humans continually look for ways to increase their efficency or otherwise minimize cognitive and physical workload (MAKE SURE THIS IS A GOOD DEFINITION OF COST ESTIMATION); The global economy likewise . . . These principles extend directly to the research and development of AI. Human cognitive and financial energy form selective pressures to artificial intelligence survival.

The foregoing analysis prompts the question:

\begin{center}
Can we make AI systems that autonomously minimize their own energetic demands?
\end{center}

The objective is not only to minimize loss, but every step of optimization: data collection, training ops, compute allocation, and even financial cost minimization. Most AI systems are blind to their own demands: production optimizers recieve little feedback, and few learn to interpret validation-hyperparameter metrics the way a machine learning engineer does; while roboticists are keenly aware of the  tight energy budget, embodied reinforcement learning agents are simultated as if energy is an inexhaustable resource;\footnote{It is beneficial though that purely unsupervised information theoretic objective such as curiosity, empowerment, and skill discovery also converge to energy minimizing behaviors. This is not coincidence though when considering the relationship information theory makes.} data hungry training loops often iterate uniformly over a training distribution when only a few peices of data have information to the model; and it's usually humans rather than AI who bear the cost function when a neural network wants to run another epoch. 

Unlike controlled, artificial intelligence, when wild, natural intelligence demands more energy than expected, it gathers, forages, or hunts independant from humans. This enables the organism to not only collect the nutrients it needs but also do so in an energy efficent manner. The dual energy-efficency, efficent-at-collecting-energy loop of animal life has proved robust over billions of years. It is very intuitive therefore to apply these concepts to a machine learning theory of information metabolism. If data is analogous to food and training, to anabolic processes, then most machine learning pipelines are infants. They are data-hungry and must be spoon-fed. On the other hand, intelligent artificial intelligence is one that learns and autonomously decides when to collect data, what kind of and how much data to collect, and when to start and stop training. 

Autonomous data collection and training would not likely collect uncountably infinite data with respect to the number of tasks it performs. Returning to the free energy principle: excessive consumption is just as taxing as unbalanced exertion. Likewise, infants pay greatest attention stimulii that are neither too boring nor suprising. Machine learning even recognizes this trend: training on stationary data must be terminated at a cetain point to prevent overfitting, mode collapse, and simply remain efficent. In deep reinforcement learning, overfitting the training reward function causes decrease in true utility, `cheating' the simulator, and learns dangerous policies. After general pretraining, efficent, autonomous data collection would likely only need well chosen, discrete samples to retain the performance of a few-shot training system. 

Sampling data before feeding it to the machine learning pipeline has the bonus of adaptive, rather than passive, data poisoning detection. With long-term memory and one shot inference capabilities, detecting one malicious data element would be sufficent to recognize arbitrarily modified pathogens in the future in a way reminiscent of the mammilian immune system.

Natural life intelligently responds to the energy scarcity of every individual day and adjusts its physiological and behavioral characteristics appropriately. This may mean sacrificing exploratory or social behaviors for more immediantly energy-rewarding ones like foraging or hunting. A remarkable adaptation of the brain when insufficently rested or otherwise taxed is that some of its individual neurons decrease their activity or even sacrifice their life to increase the energy availability for the whole. AutoML and neural architecture design already penalize static compute resource use, and sparse mixture of expert models echo similar behaviors by only dynamically routing to a subset of the model for any inference step, however the fully-energy concious AI system has yet to be realized.
    
\subsection{Thinking fast and slow \dots and slower \dots -- natural and artificial intelligence}

Dual process theory makes a dichotomy between fast, automatic, unconcious heuristics and slow, deliberate, rational thought. Togethor, these processes minimize cognitive energy expendature over a broader domain of activities than could be acheived individually. However in the greater scope of natural intelligence, these are only two frequency bands along the spectrum of optimization. Similar to (CITE D. Park), I consider this great learning spectrum in three parts: population optimization, direct learning, and indirect learning. (See Figure 2)

%%%%%%%%%%%%%whole page figure%%%%%%%%%%%%%%%%%%%%%%%%%%    
\begin{figure}
 \def\naturePopulationOptimization{\begin{itemize}
    \item Slow
    \item No individual feedback; Population is learning
    \item Organism designs selected; accompanies environment change
    \end{itemize}}
 \def\aiPopulationOptimization{\begin{itemize}
    \item Relatively slow
    \item AI not aware of this phase of optimization
    \item Humans design agent and training pipeline which often includes selecting datasets or environments
    \end{itemize}}
 \def\natureDirectLearning{\begin{itemize}
    \item Classical conditioning, culture transmission, imitation
    \item Organism learns after only a few action-stimulus pairs from real data
    \item Genetic priors shape learned behaviors
    \end{itemize}}
 \def\aiDirectLearning{\begin{itemize}
    \item Supervised learning, reinforcement learning
    \item Usually many dataset examples or environment interactions required to learn
    \item ML setup especially reward function strongly shape behavior
    \end{itemize}}
 \def\natureIndirectLearning{\begin{itemize}
    \item Imagination, Planning, Reasoning, Empathy
    \item Fast interpersonal information transmission and extremely fast internal processing
    \item Generalizes to unseen compositions, experiences, or actions
    \end{itemize}}
 \def\aiIndirectLearning{\begin{itemize}
    \item Unsupervised learning, in-context learning, zero/one/few-shot learning
    \item Would greatly reduce dataset demands
    \item This would realize the goal of transfer learning
    \end{itemize}}

 \centering
 \input{images/learning_table.pdf_tex}
 %\resizebox{\textwidth}{!}{\input{images/learning_table.pdf_tex}}
 \label{fig:2}
 \caption{Learning happens over a spectrum of frequency. Explain}
\end{figure}

\paragraph{Population optimization} begins with priors. 

\paragraph{Direct Learning} 

The reinforcement learning perspective is ``give me the agent's reward function, and I'll give you it's policy''. In the case of supervised learning, the loss function and dataset togethor comprise a reward system that biases the networks behavior in an adaptive direction. The ``crystal intelligence'' ML pipeline passes its knowledge onto the ``fluid intelligence'' neural network.

\paragraph{Indirect learning} 

    
Each of these principles of intelligence provide unique advantages to AI systems, and proofs-of-concept such as RAINBOW reinforcement learning, X, and Y demonstrate that combining multiple inductive biases into one AI system synergizes the advantages of individual ideas. However, to our knowledge, no work has combined all of them in one system. Our work, Predictive ‘General’ Intelligence, does this. 
